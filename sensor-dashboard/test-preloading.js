// Test script to verify model preloading functionality
const testModelPreloading = async () => {
  const baseUrl = 'http://localhost:3000';
  
  console.log('ğŸš€ TESTING MODEL PRELOADING');
  console.log('='*50);
  
  // Test 1: Check initial model status
  console.log('\n1ï¸âƒ£ Checking initial model status...');
  try {
    const statusResponse = await fetch(`${baseUrl}/api/models/status`);
    const statusData = await statusResponse.json();
    
    if (statusResponse.ok) {
      console.log(`âœ… Status API accessible`);
      console.log(`ğŸ“Š Models loaded: ${statusData.modelsLoaded}/${statusData.expectedModels}`);
      console.log(`ğŸ”„ Progress: ${statusData.loadingProgress}`);
      console.log(`âœ… Initialized: ${statusData.isInitialized}`);
      console.log(`ğŸ“‹ Available: ${statusData.availableModels.join(', ')}`);
    } else {
      console.log(`âŒ Status API error: ${statusData.error}`);
    }
  } catch (error) {
    console.log(`âŒ Failed to check status: ${error.message}`);
  }

  // Test 2: Force preload if needed
  console.log('\n2ï¸âƒ£ Force preloading models...');
  try {
    const preloadResponse = await fetch(`${baseUrl}/api/models/status`, {
      method: 'POST'
    });
    const preloadData = await preloadResponse.json();
    
    if (preloadResponse.ok) {
      console.log(`âœ… Force preload successful`);
      console.log(`ğŸ“Š Models loaded: ${preloadData.modelsLoaded}/${preloadData.expectedModels}`);
      console.log(`ğŸ“‹ Available: ${preloadData.availableModels.join(', ')}`);
    } else {
      console.log(`âŒ Force preload failed: ${preloadData.error}`);
    }
  } catch (error) {
    console.log(`âŒ Failed to force preload: ${error.message}`);
  }

  // Test 3: Test prediction speed (should be instant now)
  console.log('\n3ï¸âƒ£ Testing prediction speed...');
  const testData = [24.5, 25.2, 25.8];
  
  for (let i = 0; i < 3; i++) {
    try {
      const startTime = Date.now();
      
      const response = await fetch(`${baseUrl}/api/predict`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          sensorData: testData,
          modelType: 'random_forest'
        })
      });
      
      const endTime = Date.now();
      const responseTime = endTime - startTime;
      
      const result = await response.json();
      
      if (response.ok) {
        console.log(`âœ… Prediction ${i+1}: ${result.prediction} (${responseTime}ms)`);
        console.log(`   Confidence: ${(result.confidence * 100).toFixed(1)}%`);
        
        // Check if response is instant (< 50ms indicates preloaded models)
        if (responseTime < 50) {
          console.log(`   ğŸš€ FAST! Models are preloaded (${responseTime}ms)`);
        } else if (responseTime < 200) {
          console.log(`   âš¡ Good response time (${responseTime}ms)`);
        } else {
          console.log(`   â³ Slow - models may not be preloaded (${responseTime}ms)`);
        }
      } else {
        console.log(`âŒ Prediction ${i+1} failed: ${result.error}`);
        if (result.initializationStatus) {
          console.log(`   Status: ${result.initializationStatus.loadingProgress}`);
        }
      }
    } catch (error) {
      console.log(`âŒ Prediction ${i+1} error: ${error.message}`);
    }
    
    // Small delay between tests
    await new Promise(resolve => setTimeout(resolve, 100));
  }

  console.log('\nğŸ¯ PRELOADING TEST SUMMARY:');
  console.log('='*40);
  console.log('1. Models should load during server startup');
  console.log('2. Status API should show progress and completion');
  console.log('3. Predictions should be instant (< 50ms) when models are preloaded');
  console.log('4. No "models are still loading" errors after preload');
  console.log('\nâœ… If all tests pass, model preloading is working correctly!');
};

// Run the test
testModelPreloading().catch(console.error);